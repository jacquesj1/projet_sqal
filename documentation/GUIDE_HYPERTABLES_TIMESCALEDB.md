# Guide Hypertables TimescaleDB - Comment les Utiliser

## ğŸ¯ Qu'est-ce qu'une Hypertable?

Une **hypertable** est une table TimescaleDB optimisÃ©e pour les donnÃ©es **time-series** (sÃ©ries temporelles). Elle se comporte comme une table PostgreSQL normale, mais est automatiquement **partitionnÃ©e** par temps pour des performances maximales.

---

## ğŸ“Š Les 10 Hypertables du SystÃ¨me

### Ã‰tat Actuel (08 Jan 2026):

| Hypertable | Groupe | Rows | Statut | Utilisation |
|------------|--------|------|--------|-------------|
| **gavage_data_lots** âœ… | Gaveurs | 1536 | ACTIVE | DonnÃ©es gavage niveau LOT (principale) |
| **doses_journalieres** âœ… | Euralis | 8 | ACTIVE | Dashboard Euralis |
| **sqal_sensor_samples** âœ… | SQAL | 30 | ACTIVE | Capteurs IoT temps rÃ©el |
| **gavage_data** âŒ | Gaveurs | 175 | Ã€ SUPPRIMER | ObsolÃ¨te (canards individuels) |
| **gavage_lot_quotidien** âŒ | Gaveurs | ? | Ã€ SUPPRIMER | ObsolÃ¨te (remplacÃ©e par doses_journalieres) |
| **alertes** âš ï¸ | Gaveurs | ? | Ã€ MIGRER | Alertes canards â†’ lots |
| **alertes_euralis** âœ… | Euralis | 0 | OK | Alertes Euralis |
| **consumer_feedbacks** âœ… | Consumer | 0 | OK | Feedbacks consommateurs |
| **sqal_alerts** âœ… | SQAL | 0 | OK | Alertes qualitÃ© |
| **blockchain** âœ… | Blockchain | 0 | OK | Transactions blockchain |

---

## ğŸš€ Comment Utiliser les Hypertables

### 1. Insertion de DonnÃ©es (Comme Table Normale)

```sql
-- Exemple 1: InsÃ©rer donnÃ©es gavage (hypertable gavage_data_lots)
INSERT INTO gavage_data_lots (
    time,                    -- â† TOUJOURS timestamp actuel ou spÃ©cifique
    lot_gavage_id,
    jour_gavage,
    repas,
    dose_moyenne,
    dose_theorique,
    poids_moyen_lot,
    nb_canards_vivants,
    taux_mortalite,
    temperature_stabule,
    humidite_stabule
) VALUES (
    NOW(),                   -- â† Temps actuel
    3472,                    -- ID du lot LL2601001
    5,                       -- Jour 5
    'matin',                 -- Repas du matin
    305.50,                  -- Dose moyenne
    300.00,                  -- Dose thÃ©orique
    5250.00,                 -- Poids moyen
    45,                      -- Canards vivants
    2.17,                    -- Taux mortalitÃ©
    18.5,                    -- TempÃ©rature
    65.0                     -- HumiditÃ©
);

-- Exemple 2: InsÃ©rer capteur SQAL (hypertable sqal_sensor_samples)
INSERT INTO sqal_sensor_samples (
    time,
    device_id,
    lot_id,
    sample_type,
    quality_grade,
    tof_zone_0_0, tof_zone_0_1, ...,  -- 64 valeurs ToF
    spectral_415nm, spectral_445nm, ...  -- 10 canaux spectraux
) VALUES (
    NOW(),
    'ESP32_DEMO_01',
    3472,
    'foie_entier',
    'A+',
    120, 125, ...,          -- Distances ToF en mm
    15000, 18000, ...       -- Valeurs spectrales
);
```

### 2. RequÃªtes (Comme Table Normale + Optimisations Temps)

```sql
-- âœ… BON: Filtrer par temps (utilise partitionnement)
SELECT *
FROM gavage_data_lots
WHERE time > NOW() - INTERVAL '7 days'
  AND lot_gavage_id = 3472
ORDER BY time DESC;

-- âœ… BON: AgrÃ©gation sur pÃ©riode
SELECT
    time_bucket('1 hour', time) AS hour,
    AVG(dose_moyenne) as dose_avg,
    MAX(poids_moyen_lot) as poids_max
FROM gavage_data_lots
WHERE time > NOW() - INTERVAL '24 hours'
GROUP BY hour
ORDER BY hour DESC;

-- âŒ MAUVAIS: Sans filtre temps (scan toutes les partitions)
SELECT * FROM gavage_data_lots WHERE lot_gavage_id = 3472;
-- Ajouter TOUJOURS un filtre temps!
```

### 3. Fonctions TimescaleDB SpÃ©ciales

#### `time_bucket()` - AgrÃ©gation par intervalles
```sql
-- Moyennes horaires
SELECT
    time_bucket('1 hour', time) AS hour,
    lot_gavage_id,
    AVG(dose_moyenne) as dose_moyenne_horaire,
    AVG(poids_moyen_lot) as poids_moyen_horaire
FROM gavage_data_lots
WHERE time > NOW() - INTERVAL '7 days'
GROUP BY hour, lot_gavage_id
ORDER BY hour DESC;

-- Moyennes journaliÃ¨res
SELECT
    time_bucket('1 day', time) AS day,
    COUNT(*) as nb_repas,
    AVG(dose_moyenne) as dose_moyenne_journaliere
FROM gavage_data_lots
WHERE time > NOW() - INTERVAL '30 days'
GROUP BY day
ORDER BY day DESC;
```

#### `first()` et `last()` - PremiÃ¨re/derniÃ¨re valeur
```sql
-- DerniÃ¨re dose pour chaque lot
SELECT
    lot_gavage_id,
    last(dose_moyenne, time) as derniere_dose,
    last(time, time) as timestamp_derniere_dose
FROM gavage_data_lots
WHERE time > NOW() - INTERVAL '7 days'
GROUP BY lot_gavage_id;
```

#### `histogram()` - Distribution des valeurs
```sql
-- Distribution des doses
SELECT histogram(dose_moyenne, 250, 450, 10)
FROM gavage_data_lots
WHERE time > NOW() - INTERVAL '7 days';
```

### 4. Continuous Aggregates (Vues MatÃ©rialisÃ©es Auto-Refresh)

```sql
-- CrÃ©er agrÃ©gat continu pour stats horaires gavage
CREATE MATERIALIZED VIEW gavage_stats_hourly
WITH (timescaledb.continuous) AS
SELECT
    time_bucket('1 hour', time) AS hour,
    lot_gavage_id,
    AVG(dose_moyenne) as dose_moyenne,
    AVG(poids_moyen_lot) as poids_moyen,
    MAX(taux_mortalite) as taux_mortalite_max,
    COUNT(*) as nb_repas
FROM gavage_data_lots
GROUP BY hour, lot_gavage_id;

-- Politique de refresh automatique (toutes les heures)
SELECT add_continuous_aggregate_policy('gavage_stats_hourly',
    start_offset => INTERVAL '3 hours',
    end_offset => INTERVAL '1 hour',
    schedule_interval => INTERVAL '1 hour');

-- RequÃªte ultra-rapide (lit la vue prÃ©-calculÃ©e)
SELECT * FROM gavage_stats_hourly
WHERE hour > NOW() - INTERVAL '7 days'
ORDER BY hour DESC;
```

### 5. Compression Automatique (Ã‰conomie d'Espace)

```sql
-- Activer compression (donnÃ©es > 7 jours)
ALTER TABLE gavage_data_lots SET (
    timescaledb.compress,
    timescaledb.compress_segmentby = 'lot_gavage_id',
    timescaledb.compress_orderby = 'time DESC'
);

-- Politique de compression automatique
SELECT add_compression_policy('gavage_data_lots', INTERVAL '7 days');

-- VÃ©rifier taux de compression
SELECT
    pg_size_pretty(before_compression_total_bytes) as size_before,
    pg_size_pretty(after_compression_total_bytes) as size_after,
    ROUND((1 - after_compression_total_bytes::numeric / before_compression_total_bytes::numeric) * 100, 2) as compression_ratio
FROM timescaledb_information.compression_settings
WHERE hypertable_name = 'gavage_data_lots';
```

### 6. Retention Policies (Suppression Auto Anciennes DonnÃ©es)

```sql
-- Supprimer automatiquement donnÃ©es > 1 an
SELECT add_retention_policy('gavage_data_lots', INTERVAL '365 days');

-- VÃ©rifier politique
SELECT * FROM timescaledb_information.jobs
WHERE proc_name = 'policy_retention';
```

---

## ğŸ“ˆ Cas d'Usage Concrets

### Use Case 1: Dashboard Temps RÃ©el Gavage

```sql
-- DerniÃ¨res 24h de gavage pour un lot
SELECT
    time,
    jour_gavage,
    repas,
    dose_moyenne,
    poids_moyen_lot,
    nb_canards_vivants,
    taux_mortalite
FROM gavage_data_lots
WHERE lot_gavage_id = 3472
  AND time > NOW() - INTERVAL '24 hours'
ORDER BY time DESC;

-- Ã‰volution du poids moyen par jour
SELECT
    jour_gavage,
    AVG(poids_moyen_lot) as poids_moyen,
    AVG(dose_moyenne) as dose_moyenne
FROM gavage_data_lots
WHERE lot_gavage_id = 3472
GROUP BY jour_gavage
ORDER BY jour_gavage;
```

### Use Case 2: Dashboard SQAL QualitÃ© Temps RÃ©el

```sql
-- Derniers 100 Ã©chantillons SQAL
SELECT
    time,
    device_id,
    sample_type,
    quality_grade,
    spectral_415nm,
    spectral_630nm,
    tof_zone_3_3  -- Centre de la matrice 8x8
FROM sqal_sensor_samples
WHERE time > NOW() - INTERVAL '1 hour'
ORDER BY time DESC
LIMIT 100;

-- Distribution des grades qualitÃ© (derniÃ¨res 24h)
SELECT
    quality_grade,
    COUNT(*) as count,
    ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER(), 2) as percentage
FROM sqal_sensor_samples
WHERE time > NOW() - INTERVAL '24 hours'
GROUP BY quality_grade
ORDER BY quality_grade;
```

### Use Case 3: Alertes en Temps RÃ©el

```sql
-- DÃ©tecter mortalitÃ© anormale (> 3%)
INSERT INTO alertes_euralis (
    time,
    lot_id,
    type_alerte,
    criticite,
    titre,
    description,
    valeur_observee
)
SELECT
    NOW(),
    lot_gavage_id,
    'mortalite_elevee',
    'critique',
    'Taux de mortalitÃ© anormal',
    'Taux de mortalitÃ© supÃ©rieur Ã  3%: ' || taux_mortalite::text || '%',
    taux_mortalite
FROM gavage_data_lots
WHERE time = (SELECT MAX(time) FROM gavage_data_lots WHERE lot_gavage_id = 3472)
  AND taux_mortalite > 3.0
  AND lot_gavage_id = 3472;
```

### Use Case 4: Analyse Historique

```sql
-- Comparer performance lots similaires (30 derniers jours)
SELECT
    lg.code_lot,
    lg.genetique,
    AVG(gdl.dose_moyenne) as dose_moyenne,
    AVG(gdl.poids_moyen_lot) as poids_moyen,
    MAX(gdl.taux_mortalite) as taux_mortalite_max
FROM gavage_data_lots gdl
JOIN lots_gavage lg ON gdl.lot_gavage_id = lg.id
WHERE gdl.time > NOW() - INTERVAL '30 days'
  AND lg.genetique = 'mulard'
GROUP BY lg.code_lot, lg.genetique
ORDER BY dose_moyenne DESC;
```

---

## ğŸ”§ Maintenance et Monitoring

### VÃ©rifier Ã‰tat Hypertables

```sql
-- Liste toutes les hypertables avec stats
SELECT
    h.hypertable_name,
    h.num_dimensions,
    c.total_chunks,
    pg_size_pretty(h.total_bytes) as total_size,
    pg_size_pretty(h.index_bytes) as index_size
FROM timescaledb_information.hypertables h
LEFT JOIN timescaledb_information.hypertables c ON h.hypertable_name = c.hypertable_name
ORDER BY h.total_bytes DESC;
```

### VÃ©rifier Chunks (Partitions)

```sql
-- Voir les chunks d'une hypertable
SELECT
    chunk_name,
    range_start,
    range_end,
    pg_size_pretty(total_bytes) as size
FROM timescaledb_information.chunks
WHERE hypertable_name = 'gavage_data_lots'
ORDER BY range_start DESC
LIMIT 10;
```

### Forcer Compression Manuelle

```sql
-- Compresser chunks spÃ©cifiques
SELECT compress_chunk(i.show_chunks)
FROM show_chunks('gavage_data_lots', older_than => INTERVAL '7 days') i;
```

---

## âš ï¸ Bonnes Pratiques

### âœ… Ã€ FAIRE:

1. **Toujours filtrer par temps** dans les requÃªtes
2. **Utiliser time_bucket()** pour agrÃ©gations
3. **CrÃ©er continuous aggregates** pour requÃªtes frÃ©quentes
4. **Activer compression** pour Ã©conomiser espace
5. **DÃ©finir retention policies** pour nettoyer anciennes donnÃ©es

### âŒ Ã€ Ã‰VITER:

1. âŒ RequÃªtes sans filtre temps (scan complet)
2. âŒ UPDATE massifs (hypertables optimisÃ©es pour INSERT)
3. âŒ DELETE frÃ©quents (utiliser retention policy)
4. âŒ Index sur toutes les colonnes (surcharge)
5. âŒ Oublier de partitionner par entitÃ© (segment_by)

---

## ğŸ“š Ressources

- [TimescaleDB Documentation](https://docs.timescale.com/)
- [Best Practices](https://docs.timescale.com/timescaledb/latest/how-to-guides/hypertables/)
- [Compression Guide](https://docs.timescale.com/timescaledb/latest/how-to-guides/compression/)
- [Continuous Aggregates](https://docs.timescale.com/timescaledb/latest/how-to-guides/continuous-aggregates/)

---

**Date**: 08 Janvier 2026
**Version**: 1.0
**Auteur**: Claude Code
