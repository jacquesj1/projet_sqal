# Guide Complet Celery - T√¢ches Asynchrones

**Date**: 08 Janvier 2026
**Version**: 1.0

---

## üìã Vue d'Ensemble

Celery est un syst√®me de **task queue** distribu√© permettant d'ex√©cuter des t√¢ches longues en arri√®re-plan sans bloquer l'API FastAPI.

### Pourquoi Celery ?

**Probl√®mes r√©solus**:
- ‚úÖ Entra√Ænements ML longs (PySR: 5-30 min, Prophet: 1-5 min)
- ‚úÖ G√©n√©ration PDF/CSV lourds (10-60 secondes)
- ‚úÖ Envoi notifications SMS/Email (2-5 secondes)
- ‚úÖ T√¢ches planifi√©es (backups quotidiens, refresh aggregates, KPIs hebdomadaires)

**Avantages vs alternatives**:
- Redis d√©j√† install√© (pas besoin de RabbitMQ)
- Production-ready (robuste, scalable)
- Monitoring int√©gr√© (Flower)
- Retry automatique + gestion erreurs
- Beat scheduler pour t√¢ches p√©riodiques

---

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        CLIENT REQUEST                            ‚îÇ
‚îÇ                  (Frontend ‚Üí FastAPI Backend)                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     FASTAPI BACKEND                             ‚îÇ
‚îÇ  POST /api/tasks/ml/pysr/train?lot_id=123                      ‚îÇ
‚îÇ  ‚Üí D√©clenche t√¢che Celery                                      ‚îÇ
‚îÇ  ‚Üí Retourne imm√©diatement: {"task_id": "abc-123"}              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        REDIS BROKER                              ‚îÇ
‚îÇ  Queue: ml_heavy                                                ‚îÇ
‚îÇ  Message: {"task": "train_pysr_async", "args": [123]}          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     CELERY WORKER                               ‚îÇ
‚îÇ  R√©cup√®re message depuis queue                                 ‚îÇ
‚îÇ  Ex√©cute: train_pysr_model(lot_id=123)                         ‚îÇ
‚îÇ  Dur√©e: 5-30 minutes                                           ‚îÇ
‚îÇ  Stocke r√©sultat dans Redis                                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   REDIS RESULT BACKEND                          ‚îÇ
‚îÇ  task_id: "abc-123"                                             ‚îÇ
‚îÇ  status: "SUCCESS"                                              ‚îÇ
‚îÇ  result: {"formula": "...", "r2_score": 0.95}                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     CLIENT POLLING                              ‚îÇ
‚îÇ  GET /api/tasks/status/abc-123                                 ‚îÇ
‚îÇ  ‚Üí {"status": "SUCCESS", "result": {...}}                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üì¶ Composants

### 1. Celery Worker
**R√¥le**: Ex√©cute les t√¢ches asynchrones
**Container**: `gaveurs_celery_worker`
**Commande**: `celery -A app.tasks.celery_app worker --concurrency=4`
**Queues**: `ml_heavy`, `ml_light`, `exports`, `notifications`, `default`

### 2. Celery Beat
**R√¥le**: Scheduler pour t√¢ches p√©riodiques
**Container**: `gaveurs_celery_beat`
**Commande**: `celery -A app.tasks.celery_app beat`
**Planification**:
- Toutes les heures: Refresh continuous aggregates
- Quotidien 3h: Backup database
- Quotidien 4h: Cleanup old tasks
- Quotidien 18h: Daily summary emails
- Hebdomadaire lundi 6h: Weekly reports
- Hebdomadaire lundi 7h: Weekly KPIs
- Mensuel 1er √† 2h: ML models retraining

### 3. Flower
**R√¥le**: UI monitoring des t√¢ches Celery
**Container**: `gaveurs_flower`
**URL**: http://localhost:5555
**Auth**: `admin:gaveurs_flower_2024`

### 4. Redis
**R√¥le**: Broker (queues) + Result backend (r√©sultats)
**Container**: `gaveurs_redis`
**Databases**:
- DB 0: Broker (messages queue)
- DB 1: Result backend (r√©sultats t√¢ches)

---

## üìÇ Structure Fichiers

```
backend-api/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ tasks/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                    # Package init
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ celery_app.py                  # Configuration Celery
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ml_tasks.py                    # T√¢ches ML (9 t√¢ches)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ export_tasks.py                # T√¢ches export (8 t√¢ches)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ notification_tasks.py          # T√¢ches notifications (6 t√¢ches)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scheduled_tasks.py             # T√¢ches planifi√©es (7 t√¢ches)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ routers/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tasks.py                       # API routes gestion t√¢ches
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ main.py                            # Include router tasks
‚îÇ
‚îî‚îÄ‚îÄ requirements.txt                       # D√©pendances Celery
```

---

## üéØ T√¢ches Impl√©ment√©es

### ML Tasks (9 t√¢ches)

| T√¢che | Fonction | Dur√©e | Queue |
|-------|----------|-------|-------|
| PySR Training | `train_pysr_async(lot_id)` | 5-30 min | ml_heavy |
| Feeding Curve Optimization | `optimize_feeding_curve_async(lot_id)` | 2-10 min | ml_heavy |
| Prophet Forecasting | `train_prophet_async(site_code, horizon_days)` | 1-5 min | ml_light |
| Gaveur Clustering | `cluster_gaveurs_async()` | 1-3 min | ml_light |
| Anomaly Detection | `detect_anomalies_async(site_code)` | 30s-2min | ml_light |
| Anomaly Detection (periodic) | `detect_anomalies_periodic()` | 2-5 min | ml_light |
| Abattage Planning Optimization | `optimize_abattage_planning_async(date_debut, date_fin)` | 2-10 min | ml_heavy |
| Full ML Retraining | `retrain_all_ml_models_async()` | 30-60 min | ml_heavy |

### Export Tasks (8 t√¢ches)

| T√¢che | Fonction | Dur√©e | Queue |
|-------|----------|-------|-------|
| Lot PDF Report | `generate_lot_pdf_report(lot_id, report_type)` | 10-60s | exports |
| Site PDF Report | `generate_site_pdf_report(site_code, date_debut, date_fin)` | 20-90s | exports |
| Gavage CSV Export | `export_gavage_data_csv(lot_id, date_debut, date_fin)` | 5-30s | exports |
| SQAL CSV Export | `export_sqal_data_csv(lot_id, date_debut, date_fin)` | 5-30s | exports |
| Consumer Feedbacks CSV Export | `export_consumer_feedbacks_csv(date_debut, date_fin)` | 5-20s | exports |
| Blockchain Certificate | `generate_blockchain_certificate(lot_id, certificate_type)` | 2-10s | exports |
| Batch Lots CSV Export | `batch_export_lots_csv(lot_ids)` | 10-60s | exports |
| Weekly Reports Generation | `weekly_reports_generation()` | 2-5 min | exports |

### Notification Tasks (6 t√¢ches)

| T√¢che | Fonction | Dur√©e | Queue |
|-------|----------|-------|-------|
| SMS Alert | `send_sms_alert(phone, message, priority)` | 2-5s | notifications |
| Email Notification | `send_email_notification(to_email, subject, body_html)` | 1-3s | notifications |
| Anomaly Alert | `send_anomaly_alert(site_code, anomalies)` | 5-10s | notifications |
| Lot Completion Notification | `send_lot_completion_notification(lot_id)` | 3-5s | notifications |
| Daily Summary Reports | `send_daily_summary_reports()` | 20-60s | notifications |
| Consumer Feedback Acknowledgment | `send_consumer_feedback_acknowledgment(feedback_id)` | 2-3s | notifications |

### Scheduled Tasks (7 t√¢ches)

| T√¢che | Fonction | Schedule | Dur√©e |
|-------|----------|----------|-------|
| Refresh Continuous Aggregates | `refresh_continuous_aggregates()` | Hourly | 2-5 min |
| Database Backup | `backup_database_task()` | Daily 3h | 5-10 min |
| Cleanup Old Tasks | `cleanup_old_celery_tasks()` | Daily 4h | 1-3 min |
| Weekly KPIs Calculation | `calculate_weekly_kpis()` | Monday 7h | 5-30 min |
| Monthly ML Retraining | `monthly_ml_models_retraining()` | 1st of month 2h | 30-60 min |
| Cleanup Old Sensor Data | `cleanup_old_sensor_data()` | 1st of month 5h | 2-5 min |
| Health Check Periodic | `health_check_periodic()` | Every 6h | 10-30s |

---

## üöÄ Utilisation

### D√©marrage Services

```bash
# D√©marrer tous les services (incluant Celery)
docker-compose up -d

# V√©rifier statut
docker-compose ps

# Services Celery:
# - gaveurs_celery_worker   (worker)
# - gaveurs_celery_beat     (scheduler)
# - gaveurs_flower          (monitoring)
```

### D√©clencher une T√¢che via API

#### Exemple 1: Entra√Ænement PySR
```bash
# D√©clencher entra√Ænement
curl -X POST "http://localhost:8000/api/tasks/ml/pysr/train?lot_id=3472"

# R√©ponse:
{
  "status": "submitted",
  "task_id": "abc-123-def-456",
  "lot_id": 3472,
  "message": "PySR training started"
}

# V√©rifier statut
curl "http://localhost:8000/api/tasks/status/abc-123-def-456"

# R√©ponse (en cours):
{
  "task_id": "abc-123-def-456",
  "task_name": "train_pysr_async",
  "status": "STARTED",
  "progress": 45,
  "started_at": "2026-01-08T12:30:00"
}

# R√©ponse (termin√©):
{
  "task_id": "abc-123-def-456",
  "task_name": "train_pysr_async",
  "status": "SUCCESS",
  "result": {
    "status": "success",
    "lot_id": 3472,
    "formula": "ITM = 0.85 * poids_final - 0.12 * dose_totale + 42.3",
    "r2_score": 0.947,
    "variables": ["poids_final", "dose_totale"],
    "complexity": 7
  },
  "completed_at": "2026-01-08T12:45:23"
}
```

#### Exemple 2: Export PDF
```bash
# G√©n√©rer rapport PDF pour un lot
curl -X POST "http://localhost:8000/api/tasks/export/pdf/lot?lot_id=3472&report_type=complete"

# R√©ponse:
{
  "status": "submitted",
  "task_id": "xyz-789-abc-012",
  "lot_id": 3472,
  "report_type": "complete",
  "message": "PDF generation started"
}

# R√©cup√©rer r√©sultat
curl "http://localhost:8000/api/tasks/status/xyz-789-abc-012"

# R√©ponse:
{
  "task_id": "xyz-789-abc-012",
  "status": "SUCCESS",
  "result": {
    "status": "success",
    "lot_id": 3472,
    "report_type": "complete",
    "pdf_url": "/exports/reports/lot_3472_complete_20260108.pdf",
    "file_size": 523847,
    "generated_at": "2026-01-08T13:15:42"
  }
}

# T√©l√©charger PDF
curl "http://localhost:8000/exports/reports/lot_3472_complete_20260108.pdf" -o rapport.pdf
```

#### Exemple 3: Notification SMS
```bash
# Envoyer SMS d'alerte
curl -X POST "http://localhost:8000/api/tasks/notifications/sms" \
  -H "Content-Type: application/json" \
  -d '{
    "phone": "+33612345678",
    "message": "‚ö†Ô∏è Alerte: Taux mortalit√© √©lev√© sur lot LL2601001 (3.2%)",
    "priority": "high"
  }'

# R√©ponse:
{
  "status": "submitted",
  "task_id": "sms-456-def-789",
  "phone": "+33612345678",
  "message": "SMS sending started"
}
```

### Monitoring avec Flower

```bash
# Acc√©der √† Flower
http://localhost:5555

# Auth: admin / gaveurs_flower_2024
```

**Features Flower**:
- üìä Dashboard temps r√©el (t√¢ches actives, succ√®s/√©checs)
- üìà Graphiques performance workers
- üîç Historique t√¢ches (succ√®s, √©checs, retry)
- ‚è±Ô∏è Dur√©e moyenne par type de t√¢che
- üìã D√©tails complets d'une t√¢che (args, kwargs, traceback)
- üîÑ Retry/Revoke t√¢ches

---

## üìä Statistiques API

### GET /api/tasks/stats

R√©cup√®re statistiques globales Celery.

```bash
curl "http://localhost:8000/api/tasks/stats"

# R√©ponse:
{
  "workers": ["celery@gaveurs_celery_worker"],
  "nb_workers": 1,
  "tasks_active": 3,
  "tasks_scheduled": 5,
  "tasks_reserved": 2,
  "total_pending": 10,
  "worker_stats": {
    "celery@gaveurs_celery_worker": {
      "total": {
        "ml_heavy": 150,
        "ml_light": 450,
        "exports": 280,
        "notifications": 520
      },
      "pool": {
        "max-concurrency": 4,
        "processes": [12345, 12346, 12347, 12348]
      }
    }
  }
}
```

### GET /api/tasks/list/active

Liste t√¢ches en cours (PENDING, STARTED).

```bash
curl "http://localhost:8000/api/tasks/list/active?limit=10"

# R√©ponse:
{
  "total": 3,
  "tasks": [
    {
      "task_id": "abc-123",
      "task_name": "train_pysr_async",
      "status": "STARTED",
      "worker": "celery@gaveurs_celery_worker",
      "started_at": "2026-01-08T12:30:00"
    },
    {
      "task_id": "def-456",
      "task_name": "generate_lot_pdf_report",
      "status": "STARTED",
      "worker": "celery@gaveurs_celery_worker",
      "started_at": "2026-01-08T12:32:15"
    },
    {
      "task_id": "ghi-789",
      "task_name": "send_email_notification",
      "status": "PENDING",
      "eta": "2026-01-08T12:35:00"
    }
  ]
}
```

### DELETE /api/tasks/cancel/{task_id}

Annule une t√¢che en cours.

```bash
curl -X DELETE "http://localhost:8000/api/tasks/cancel/abc-123"

# R√©ponse:
{
  "status": "cancelled",
  "task_id": "abc-123",
  "message": "Task cancellation requested"
}
```

---

## ‚öôÔ∏è Configuration

### Beat Schedule (T√¢ches P√©riodiques)

Fichier: `backend-api/app/tasks/celery_app.py`

```python
celery_app.conf.beat_schedule = {
    # Toutes les heures
    'refresh-continuous-aggregates-hourly': {
        'task': 'app.tasks.scheduled_tasks.refresh_continuous_aggregates',
        'schedule': crontab(minute=0),  # Toutes les heures √† :00
    },

    # Quotidien 3h
    'backup-database-daily': {
        'task': 'app.tasks.scheduled_tasks.backup_database_task',
        'schedule': crontab(hour=3, minute=0),
    },

    # Quotidien 4h
    'cleanup-old-tasks-daily': {
        'task': 'app.tasks.scheduled_tasks.cleanup_old_celery_tasks',
        'schedule': crontab(hour=4, minute=0),
    },

    # Quotidien 18h
    'daily-summary-reports': {
        'task': 'app.tasks.notification_tasks.send_daily_summary_reports',
        'schedule': crontab(hour=18, minute=0),
    },

    # Hebdomadaire lundi 6h
    'weekly-reports-generation': {
        'task': 'app.tasks.export_tasks.weekly_reports_generation',
        'schedule': crontab(hour=6, minute=0, day_of_week=1),  # Lundi
    },

    # Hebdomadaire lundi 7h
    'weekly-kpis-calculation': {
        'task': 'app.tasks.scheduled_tasks.calculate_weekly_kpis',
        'schedule': crontab(hour=7, minute=0, day_of_week=1),
    },

    # Mensuel 1er du mois √† 2h
    'monthly-ml-retraining': {
        'task': 'app.tasks.scheduled_tasks.monthly_ml_models_retraining',
        'schedule': crontab(hour=2, minute=0, day_of_month=1),
    },

    # Mensuel 1er du mois √† 5h
    'cleanup-old-sensor-data': {
        'task': 'app.tasks.scheduled_tasks.cleanup_old_sensor_data',
        'schedule': crontab(hour=5, minute=0, day_of_month=1),
    },

    # Toutes les 6h
    'health-check-periodic': {
        'task': 'app.tasks.scheduled_tasks.health_check_periodic',
        'schedule': crontab(minute=0, hour='*/6'),
    },

    # Toutes les 6h (anomalies)
    'anomalies-detection-periodic': {
        'task': 'app.tasks.ml_tasks.detect_anomalies_periodic',
        'schedule': crontab(minute=0, hour='*/6'),
    }
}
```

### Task Routing (Queues)

```python
celery_app.conf.task_routes = {
    # ML Tasks Lourds ‚Üí Queue ml_heavy
    'app.tasks.ml_tasks.train_pysr_async': {'queue': 'ml_heavy'},
    'app.tasks.ml_tasks.optimize_feeding_curve_async': {'queue': 'ml_heavy'},
    'app.tasks.ml_tasks.optimize_abattage_planning_async': {'queue': 'ml_heavy'},
    'app.tasks.ml_tasks.retrain_all_ml_models_async': {'queue': 'ml_heavy'},

    # ML Tasks L√©gers ‚Üí Queue ml_light
    'app.tasks.ml_tasks.train_prophet_async': {'queue': 'ml_light'},
    'app.tasks.ml_tasks.cluster_gaveurs_async': {'queue': 'ml_light'},
    'app.tasks.ml_tasks.detect_anomalies_async': {'queue': 'ml_light'},

    # Exports ‚Üí Queue exports
    'app.tasks.export_tasks.*': {'queue': 'exports'},

    # Notifications ‚Üí Queue notifications
    'app.tasks.notification_tasks.*': {'queue': 'notifications'},

    # Scheduled ‚Üí Queue default
    'app.tasks.scheduled_tasks.*': {'queue': 'default'}
}
```

---

## üîß Troubleshooting

### Worker ne d√©marre pas

```bash
# V√©rifier logs
docker logs gaveurs_celery_worker

# Erreurs communes:
# 1. Redis non disponible ‚Üí Attendre que Redis d√©marre
# 2. Import error ‚Üí V√©rifier requirements.txt install√©s
# 3. Database connection ‚Üí V√©rifier DATABASE_URL
```

### T√¢che bloqu√©e en PENDING

```bash
# V√©rifier worker en cours d'ex√©cution
docker ps | grep celery_worker

# V√©rifier queues Redis
docker exec -it gaveurs_redis redis-cli
> LLEN celery  # Nombre messages en queue
> LPOP celery  # R√©cup√©rer premier message

# Red√©marrer worker
docker restart gaveurs_celery_worker
```

### T√¢che √©chou√©e (FAILURE)

```bash
# R√©cup√©rer erreur via API
curl "http://localhost:8000/api/tasks/status/task-id-failed"

# R√©ponse:
{
  "status": "FAILURE",
  "error": "ConnectionError: Database connection lost"
}

# V√©rifier logs worker
docker logs gaveurs_celery_worker --tail 50

# Retry manuel
curl -X POST "http://localhost:8000/api/tasks/ml/pysr/train?lot_id=3472"
```

### Beat ne d√©clenche pas t√¢ches planifi√©es

```bash
# V√©rifier Beat en cours
docker ps | grep celery_beat

# V√©rifier logs Beat
docker logs gaveurs_celery_beat --tail 50

# Doit afficher:
# [2026-01-08 12:00:00,123: INFO/MainProcess] Scheduler: Sending due task refresh-continuous-aggregates-hourly

# V√©rifier schedule configur√©
docker exec -it gaveurs_celery_beat celery -A app.tasks.celery_app inspect scheduled

# Red√©marrer Beat
docker restart gaveurs_celery_beat
```

---

## üìö Ressources

- [Celery Documentation](https://docs.celeryproject.org/)
- [Celery Best Practices](https://docs.celeryproject.org/en/stable/userguide/tasks.html#tips-and-best-practices)
- [Flower Documentation](https://flower.readthedocs.io/)
- [Redis Documentation](https://redis.io/documentation)

---

**Auteur**: Claude Code
**Date**: 08 Janvier 2026
**Statut**: ‚úÖ Impl√©mentation compl√®te
