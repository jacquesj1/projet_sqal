# √âtapes d'Import CSV - Lots R√©els Euralis

**Date**: 12 Janvier 2026
**Objectif**: Importer 75 lots r√©els depuis CSV Euralis + g√©n√©rer donn√©es SQAL

---

## R√©sum√© des Changements

### 1. Network Graph - 20 Variables ‚úÖ TERMIN√â

Le Network Graph de corr√©lations a √©t√© √©tendu de 16 √† **20 variables** :

**Nouvelles variables CSV ajout√©es** :
- `poids_foie_reel` - Poids foie r√©el (Poids_de_foies_moyen)
- `total_corn` - Dose totale ma√Øs (total_cornReal)
- `nb_morts` - Mortalit√© gavage (Nb_MEG)
- `sigma` - Homog√©n√©it√© lot (Ecart_Type_Foie_Lot)

**Fichier modifi√©** : [gaveurs-frontend/components/analytics/NetworkGraphCorrelations.tsx](gaveurs-frontend/components/analytics/NetworkGraphCorrelations.tsx)

**Changements** :
- ‚úÖ Ajout des 4 variables dans `variables` object (lignes 80-84)
- ‚úÖ Population des variables avec donn√©es CSV r√©elles (lignes 135-139)
- ‚úÖ Labels fran√ßais ajout√©s (lignes 266-269)
- ‚úÖ Cat√©gorisation : 3 variables dans cat√©gorie 'csv', sigma dans 'performance'
- ‚úÖ Couleur orange (#f97316) pour cat√©gorie CSV
- ‚úÖ Force de r√©pulsion augment√©e de -1200 √† -1400 pour 20 n≈ìuds

---

## 2. Migration Base de Donn√©es - Colonnes CSV ‚è≥ EN ATTENTE

### Option A : Via Endpoint API (Recommand√©)

**Pr√©requis** : Red√©marrer le backend pour charger le nouvel endpoint

1. **Arr√™ter le backend** (Ctrl+C dans le terminal backend)

2. **Red√©marrer le backend** :
   ```bash
   cd backend-api
   python -m uvicorn app.main:app --reload --port 8000
   ```

3. **Ex√©cuter la migration** :
   ```bash
   curl -X POST "http://localhost:8000/api/lots/migrate/csv-columns" -H "Content-Type: application/json"
   ```

**R√©sultat attendu** :
```json
{
  "status": "success",
  "message": "Migration CSV columns completed",
  "columns": [
    {"column_name": "nb_meg", "data_type": "integer", "column_default": "0"},
    {"column_name": "poids_foie_moyen_g", "data_type": "numeric", "column_default": null},
    {"column_name": "total_corn_real_g", "data_type": "numeric", "column_default": null}
  ]
}
```

### Option B : Via pgAdmin / SQL

Si l'option A ne fonctionne pas :

1. Ouvrir **pgAdmin**
2. Se connecter √† `gaveurs_db`
3. Ouvrir **Query Tool**
4. Ex√©cuter le fichier : [backend-api/scripts/migration_add_csv_columns.sql](backend-api/scripts/migration_add_csv_columns.sql)

**Colonnes ajout√©es** :
- `total_corn_real_g` DECIMAL(10,2) - Quantit√© totale de ma√Øs ing√©r√©e
- `nb_meg` INTEGER DEFAULT 0 - Mortalit√© en gavage
- `poids_foie_moyen_g` DECIMAL(8,2) - Poids moyen des foies

---

## 3. Import CSV - 75 Lots R√©els ‚è≥ PR√äT √Ä EX√âCUTER

### Scripts Cr√©√©s

1. **Script Python** : [backend-api/scripts/import_csv_real_data.py](backend-api/scripts/import_csv_real_data.py) (373 lignes)
2. **Script Windows** : [backend-api/scripts/import_csv_data.bat](backend-api/scripts/import_csv_data.bat)
3. **Documentation** : [backend-api/scripts/README_IMPORT_CSV.md](backend-api/scripts/README_IMPORT_CSV.md)

### Fichier Source

- **CSV** : [backend-api/data/2023/Pretraite_End_2024_claude.csv](backend-api/data/2023/Pretraite_End_2024_claude.csv)
- **Contenu** : 75 lots r√©els + 174 colonnes
- **P√©riode** : Janvier - F√©vrier 2024

### Ex√©cution (Windows)

**Dry-run** (pr√©visualisation sans insertion) :
```cmd
cd backend-api
scripts\import_csv_data.bat --dry-run
```

**Import r√©el** :
```cmd
scripts\import_csv_data.bat
```

### Ex√©cution (Linux/Mac)

```bash
cd backend-api
source venv/bin/activate
python scripts/import_csv_real_data.py --dry-run  # Pr√©visualisation
python scripts/import_csv_real_data.py             # Import r√©el
```

### R√©sultats Attendus

- **74-75 lots** import√©s dans table `lots_gavage`
- **~1200 enregistrements** dans table `gavage_lot_quotidien` (historique jour par jour)
- **~30 gaveurs** cr√©√©s/r√©utilis√©s dans table `gaveurs`

**V√©rification SQL** :
```sql
-- Compter les lots import√©s
SELECT COUNT(*) as nb_lots,
       COUNT(DISTINCT gaveur_id) as nb_gaveurs,
       MIN(date_debut_gavage) as premiere_date,
       MAX(date_debut_gavage) as derniere_date
FROM lots
WHERE code_lot LIKE 'LL%';

-- Attendu: 74-75 lots, ~30 gaveurs, dates: 2024-01-05 √† 2024-01-31
```

---

## 4. G√©n√©ration SQAL - Lots CSV ‚è≥ PR√äT √Ä EX√âCUTER

### Scripts Cr√©√©s

1. **Script modifi√©** : [backend-api/scripts/generate_sqal_test_data.py](backend-api/scripts/generate_sqal_test_data.py)
   - Ajout de l'argument `--filter-csv`
   - Filtre SQL : `code_lot LIKE 'LL%'`

2. **Script Windows** : [backend-api/scripts/generate_sqal_on_imported_lots.bat](backend-api/scripts/generate_sqal_on_imported_lots.bat)

### Ex√©cution (Windows)

```cmd
cd backend-api
scripts\generate_sqal_on_imported_lots.bat
```

### Ex√©cution (Ligne de commande)

```bash
cd backend-api
python scripts/generate_sqal_test_data.py --nb-lots 75 --samples-per-lot 30 --filter-csv
```

**Param√®tres** :
- `--nb-lots 75` : G√©n√©rer SQAL pour 75 lots max
- `--samples-per-lot 30` : 30 √©chantillons ToF par lot
- `--filter-csv` : Cibler uniquement les lots CSV (code_lot LIKE 'LL%')

**R√©sultats attendus** :
- **75 lots** avec donn√©es SQAL dans `sqal_sample_lots`
- **~2250 √©chantillons** ToF 8x8 dans `sqal_sensor_samples`
- **Grades qualit√©** calcul√©s (A+, A, B, C, REJECT)

---

## 5. V√©rification Network Graph üéØ OBJECTIF

Une fois les √©tapes 2, 3 et 4 termin√©es :

### Acc√©der √† la page Analytics Qualit√©

```
http://localhost:3000/analytics/qualite
```

### V√©rifications Attendues

1. **20 n≈ìuds** dans le graphe de r√©seau (au lieu de 16)
2. **Nouvelles variables CSV visibles** :
   - Poids foie r√©el
   - Dose totale ma√Øs
   - Mortalit√© gavage
   - Homog√©n√©it√© lot
3. **Corr√©lations calcul√©es** entre les 20 variables
4. **Couleur orange** pour les variables CSV
5. **Donn√©es r√©elles** depuis les 75 lots import√©s

### Corr√©lations Int√©ressantes √† Observer

- **ITM ‚Üî Poids foie r√©el** : Forte corr√©lation attendue
- **Dose totale ma√Øs ‚Üî Poids foie** : Positive
- **Mortalit√© gavage ‚Üî ITM** : N√©gative (plus de morts = ITM moins bon)
- **Homog√©n√©it√© lot (sigma) ‚Üî Qualit√©** : Faible sigma = meilleure qualit√©

---

## 6. Documentation D√©mo Client ‚è≥ √Ä PR√âPARER

√Ä cr√©er apr√®s v√©rification des √©tapes 1-5 :

- **Sc√©narios de d√©mo** avec lots r√©els (LL4801665, LL4801763...)
- **Captures d'√©cran** du Network Graph 20 variables
- **Analyse des corr√©lations** entre production et qualit√©
- **Guide utilisateur** pour interpr√©ter le graphe

---

## √âtat Actuel

| √âtape | Statut | Fichiers |
|-------|--------|----------|
| 1. Network Graph 20 variables | ‚úÖ TERMIN√â | NetworkGraphCorrelations.tsx |
| 2. Migration DB colonnes CSV | ‚è≥ EN ATTENTE RED√âMARRAGE BACKEND | lots.py (endpoint POST /migrate/csv-columns) |
| 3. Import CSV 75 lots | ‚è≥ PR√äT | import_csv_real_data.py, import_csv_data.bat |
| 4. SQAL sur lots CSV | ‚è≥ PR√äT | generate_sqal_test_data.py --filter-csv |
| 5. V√©rification Network | üéØ OBJECTIF | http://localhost:3000/analytics/qualite |
| 6. Documentation d√©mo | ‚è≥ √Ä FAIRE | √Ä cr√©er |

---

## Probl√®mes Rencontr√©s

### 1. Connexion PostgreSQL depuis Python (Windows)

**Erreur** : `'utf-8' codec can't decode byte 0xe9 in position 103`

**Cause** : Probl√®me d'encodage avec psycopg2 sur Windows + URL contenant caract√®res sp√©ciaux dans le mot de passe

**Solution** : Endpoint API `/api/lots/migrate/csv-columns` cr√©√© dans le backend

### 2. Backend non red√©marr√© automatiquement

**Erreur** : Endpoint `/migrate/csv-columns` retourne 404

**Cause** : Backend lanc√© sans `--reload` ou uvicorn ne d√©tecte pas les changements

**Solution** : **Red√©marrer manuellement le backend** (√âtape 2, Option A)

---

## Commandes Rapides

### Red√©marrer tout (apr√®s migration DB)

```bash
# Terminal 1 - Backend
cd backend-api
python -m uvicorn app.main:app --reload --port 8000

# Terminal 2 - Import CSV
cd backend-api
scripts\import_csv_data.bat  # Windows
# OU: python scripts/import_csv_real_data.py  # Linux/Mac

# Terminal 3 - SQAL
cd backend-api
scripts\generate_sqal_on_imported_lots.bat  # Windows

# Terminal 4 - Frontend
cd gaveurs-frontend
npm run dev
# ‚Üí http://localhost:3000/analytics/qualite
```

---

**Auteur** : Claude Sonnet 4.5
**Date** : 12 Janvier 2026
**Session** : Continuation Analytics Phase 1
